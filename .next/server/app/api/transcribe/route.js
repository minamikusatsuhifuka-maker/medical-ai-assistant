"use strict";(()=>{var e={};e.id=93,e.ids=[93],e.modules={399:e=>{e.exports=require("next/dist/compiled/next-server/app-page.runtime.prod.js")},517:e=>{e.exports=require("next/dist/compiled/next-server/app-route.runtime.prod.js")},7073:(e,r,t)=>{t.r(r),t.d(r,{originalPathname:()=>m,patchFetch:()=>h,requestAsyncStorage:()=>d,routeModule:()=>u,serverHooks:()=>l,staticGenerationAsyncStorage:()=>c});var a={};t.r(a),t.d(a,{POST:()=>p});var o=t(9303),s=t(8716),n=t(670),i=t(7070);async function p(e){try{let r=(await e.formData()).get("audio");if(!r)return i.NextResponse.json({error:"音声ファイルがありません"},{status:400});let t=new FormData;t.append("file",r,"audio.webm"),t.append("model","whisper-1"),t.append("language","ja"),t.append("response_format","json");let a=await fetch("https://api.openai.com/v1/audio/transcriptions",{method:"POST",headers:{Authorization:`Bearer ${process.env.OPENAI_API_KEY}`},body:t});if(!a.ok){let e=await a.text();return console.error("Whisper API error:",e),i.NextResponse.json({error:"Whisper API エラー"},{status:500})}let o=await a.json();return i.NextResponse.json({text:o.text||""})}catch(e){return console.error("Transcribe error:",e),i.NextResponse.json({error:"サーバーエラー"},{status:500})}}let u=new o.AppRouteRouteModule({definition:{kind:s.x.APP_ROUTE,page:"/api/transcribe/route",pathname:"/api/transcribe",filename:"route",bundlePath:"app/api/transcribe/route"},resolvedPagePath:"/Users/tpjatpja/Desktop/medical-ai-assistant/app/api/transcribe/route.js",nextConfigOutput:"",userland:a}),{requestAsyncStorage:d,staticGenerationAsyncStorage:c,serverHooks:l}=u,m="/api/transcribe/route";function h(){return(0,n.patchFetch)({serverHooks:l,staticGenerationAsyncStorage:c})}}};var r=require("../../../webpack-runtime.js");r.C(e);var t=e=>r(r.s=e),a=r.X(0,[276,972],()=>t(7073));module.exports=a})();